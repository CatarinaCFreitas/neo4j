{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import date\n",
    "import datetime as dt\n",
    "import time\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import progressbar\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download chromedriver executable from https://chromedriver.chromium.org/home\n",
    "\n",
    "# add chromedriver path\n",
    "import sys\n",
    "path = '/Users/catarina/Projects/bin'\n",
    "sys.path.append(path)\n",
    "\n",
    "\n",
    "# 755 is the default numerical permission for files in usr/bin\n",
    "# chromedriver needs a numerical permission equivalent to or greater than 755\n",
    "import os\n",
    "os.chmod(path,755) #664\n",
    "\n",
    "\n",
    "# # configure webdriver to use browser\n",
    "from selenium import webdriver\n",
    "\n",
    "# driver = webdriver.Firefox(executable_path = path + '/geckodriver')\n",
    "# driver = webdriver.Chrome(executable_path = path + '/chromedriver')\n",
    "\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_content(website):\n",
    "    \n",
    "    driver = webdriver.Firefox(executable_path = path + '/geckodriver')\n",
    "    \n",
    "    driver.get(website)\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # scroll page until the end\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")        \n",
    "        \n",
    "        if new_height == last_height:\n",
    "            break\n",
    "            \n",
    "        last_height = new_height\n",
    "        \n",
    "        \n",
    "    content = driver.page_source\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    return soup, driver\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_personal_info(soup):\n",
    "    \n",
    "    info = {}\n",
    "    \n",
    "    has_age = soup.find(\"td\", text=\"Age\")\n",
    "    if has_age:\n",
    "        info['age'] = has_age.find_next_sibling(\"td\").text.strip().split(' ')[0]\n",
    "        \n",
    "        \n",
    "    has_birthday = soup.find(\"td\", text=\"Birthday\")\n",
    "    if has_birthday:\n",
    "        info['birthday'] = has_birthday.find_next_sibling(\"td\").text.strip()\n",
    "        \n",
    "        \n",
    "    has_height = soup.find(\"td\", text=\"Height\")\n",
    "    if has_height:\n",
    "        info['height_cm'] = has_height.find_next_sibling(\"td\").text.strip().split('(')[1].split(' ')[0]\n",
    "        \n",
    "        \n",
    "    has_weight = soup.find(\"td\", text=\"Weight\")\n",
    "    if has_weight:\n",
    "        info['weight_kg'] = has_weight.find_next_sibling(\"td\").text.strip().split('(')[1].split(' ')[0]\n",
    "        \n",
    "        \n",
    "    has_eye_color = soup.find(\"td\", text=\"Eye Color\")\n",
    "    if has_eye_color:\n",
    "        info['eye_color'] = has_eye_color.find_next_sibling(\"td\").text.strip().lower()\n",
    "        \n",
    "    \n",
    "    has_hair_color = soup.find(\"td\", text=\"Hair Color\")\n",
    "    if has_hair_color:\n",
    "        info['hair_color'] = has_hair_color.find_next_sibling(\"td\").text.strip().lower()      \n",
    "        \n",
    "        \n",
    "    has_sign = soup.find(\"td\", text=\"Zodiac Sign\")\n",
    "    if has_sign:\n",
    "        info['sign'] = has_sign.find_next_sibling(\"td\").text.strip().lower()\n",
    "        \n",
    "\n",
    "    has_sexuality = soup.find(\"td\", text=\"Sexuality\")\n",
    "    if has_sexuality:\n",
    "        info['sexuality'] = has_sexuality.find_next_sibling(\"td\").text.strip().lower()\n",
    "        \n",
    "        \n",
    "    has_ethnicity = soup.find(\"td\", text=\"Ethnicity\")\n",
    "    if has_ethnicity:\n",
    "        info['ethnicity'] = has_ethnicity.find_next_sibling(\"td\").text.strip().lower()\n",
    "        \n",
    "        \n",
    "    has_nationality = soup.find(\"td\", text=\"Nationality\")\n",
    "    if has_nationality:\n",
    "        info['nationality'] = has_nationality.find_next_sibling(\"td\").text.strip().lower()\n",
    "        \n",
    "        \n",
    "    has_occupation = soup.find(\"td\", text=\"Occupation\")\n",
    "    if has_occupation:\n",
    "        info['occupation'] = has_occupation.find_next_sibling(\"td\").text.strip().lower()\n",
    "        \n",
    "\n",
    "    has_religion = soup.find(\"td\", text=\"Religion\")\n",
    "    if has_religion:\n",
    "        info['religion'] = has_religion.find_next_sibling(\"td\").text.strip().lower()\n",
    "        \n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def extract_dating_history(soup):\n",
    "\n",
    "    relationships = []\n",
    "\n",
    "    for match in soup.findAll('td', text = re.compile('\\t\\tRelationship\\n|\\t\\tEncounter\\n|\\t\\tMarried\\n')):\n",
    "       \n",
    "        is_rumour = match.find_next_sibling(\"td\").text.strip() == 'R'\n",
    "    \n",
    "        if is_rumour:\n",
    "            continue\n",
    "        \n",
    "        name = match.find_previous_sibling(\"td\").text.strip()\n",
    "        start = match.find_next_sibling(\"td\").find_next_sibling(\"td\")\n",
    "        end = start.find_next_sibling(\"td\")\n",
    "        duration = end.find_next_sibling(\"td\").text.strip()\n",
    "        match_url = match.find_previous_sibling(\"td\").find(\"a\")['href']\n",
    "\n",
    "        relationships.append({'name': name, \n",
    "                              'type': match.text.strip(),\n",
    "                              'start': start.text.strip(), \n",
    "                              'end': end.text.strip(), \n",
    "                              'duration': duration,\n",
    "                              'url': match_url\n",
    "                             })\n",
    "\n",
    "    return relationships\n",
    "\n",
    "\n",
    "\n",
    "def extract_person_data(url):\n",
    "\n",
    "    soup, driver = get_soup_content(url)\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    i = extract_personal_info(soup)\n",
    "\n",
    "    r = extract_dating_history(soup)\n",
    "\n",
    "    i['name'] = url_to_name(url)\n",
    "\n",
    "    i['relationships'] = r\n",
    "\n",
    "    d = pd.DataFrame.from_dict(i, orient = 'index').transpose()\n",
    "    \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_popular_celebrities(driver, n):\n",
    "\n",
    "    # scroll page until listing at least 1000 celebrities\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        first_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        content = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "        last_item = soup.findAll('i', attrs={'class':'icon-chart-line'})[-1]\n",
    "\n",
    "        nr_items = int(last_item.find_next_sibling(\"span\").text.replace(',',''))\n",
    "\n",
    "        if (nr_items >= n) or (first_height == last_height):\n",
    "            \n",
    "            break\n",
    "\n",
    "\n",
    "    # extract url for details on each celebrity\n",
    "\n",
    "    urls = []\n",
    "\n",
    "    for item in soup.findAll('li', attrs={'class':'ff-grid-box ff-list'}):\n",
    "        urls.append(item.find('a')['href'])\n",
    "\n",
    "\n",
    "    return urls, nr_items\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def url_to_name(url):\n",
    "    return (' ').join([w.capitalize() for w in (url.split('/')[-1].split('-'))])\n",
    "\n",
    "\n",
    "def name_to_url(name):\n",
    "    return name.split('(')[0].strip().lower().replace(' ','-')    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_dataset(urls, df):\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        \n",
    "        final_df = df.copy()\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        final_df = pd.DataFrame(columns = ['age', 'birthday', 'height_cm', 'weight_kg', 'eye_color', \n",
    "                                           'hair_color', 'sign', 'sexuality', 'ethnicity', 'nationality',\n",
    "                                           'occupation', 'religion', 'name', 'relationships'])\n",
    "    \n",
    "    \n",
    "    bar = progressbar.ProgressBar(maxval=len(urls), \n",
    "                                  widgets=[progressbar.Bar('=', '[', ']'), ' ', \n",
    "                                           progressbar.Percentage()])\n",
    "    \n",
    "    bar.start()\n",
    "    \n",
    "    # get information from all urls\n",
    "    \n",
    "    for idx, url in enumerate(urls):\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            df = extract_person_data(url)\n",
    "\n",
    "            if df.loc[0,'name'] not in final_df.name.unique():\n",
    "\n",
    "                final_df = pd.concat([final_df, df] , axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "            # extract info from all the relationships of this celebrity if they are not already stored\n",
    "\n",
    "            for relationship in df.relationships[0]:\n",
    "\n",
    "                if relationship['name'] in final_df.name.unique():\n",
    "                    continue\n",
    "\n",
    "                df = extract_person_data(relationship['url'])\n",
    "                final_df = pd.concat([final_df, df] , axis = 0, ignore_index = True)     \n",
    "\n",
    "\n",
    "        except Exception as ex:\n",
    "            \n",
    "            print(ex)\n",
    "            \n",
    "            bar.finish()\n",
    "            \n",
    "            return final_df\n",
    "        \n",
    "        \n",
    "        bar.update(idx + 1)\n",
    "        \n",
    "    \n",
    "    bar.finish()       \n",
    "        \n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scrape urls pages of the most popular celebrities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrolling down is not always activated - manually ensure it is and restart webdriver if needed\n",
    "\n",
    "driver = webdriver.Firefox(executable_path = path + '/geckodriver')\n",
    "\n",
    "website = \"https://www.whosdatedwho.com/popular\"\n",
    "\n",
    "driver.get(website)\n",
    "\n",
    "content = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n"
     ]
    }
   ],
   "source": [
    "# run web scraping code\n",
    "\n",
    "urls, nr_items = get_n_most_popular_celebrities(driver, n = 1000)\n",
    "print(nr_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(\"popular_urls.csv\",\"w\") as f:\n",
    "    wr = csv.writer(f,delimiter=\"\\n\")\n",
    "    wr.writerow(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scrape personal info on each celebrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "# extract information from all celebrities in the urls list and from the people their were involved with\n",
    "\n",
    "data = build_dataset(urls, pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "\n",
    "data.to_csv('relationships.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('relationships.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Â Data correction\n",
    "\n",
    "data_.loc[data_.name == 'Rafael Cebrian','birthday'] = '15th October, 1989'\n",
    "data_.loc[data_.name == 'Ryan Press','birthday'] = '24th October, 1979'\n",
    "data_.loc[data_.name == 'Jessica Vargas','birthday'] = '23th October, 1995'\n",
    "data_.loc[data_.name == 'Dave Gardner','birthday'] = '17th September, 1976'\n",
    "data_.loc[data_.name == 'Tommy Alastra','birthday'] = '14th February, 1976'\n",
    "data_.loc[data_.name == 'Karolyn Pho','birthday'] = '19th January, 1998'\n",
    "data_.loc[data_.name == 'Bonita','birthday'] = '12th December, 1995'\n",
    "data_.loc[data_.name == 'Kaitlin Najjar','birthday'] = '23rd May, 1995'\n",
    "data_.loc[data_.name == 'Natt Weller','birthday'] = '10th May, 1995'\n",
    "data_.loc[data_.name == 'Kaitlin Najjar','birthday'] = '10th May, 1995'\n",
    "data_.loc[data_.name == 'Sophie Coady','birthday'] = '10th November, 1991'\n",
    "data_.loc[data_.name == 'Victor Turpin','birthday'] = '4th March, 1982'\n",
    "data_.loc[data_.name == 'Jack Street','birthday'] = '25th September, 1988'\n",
    "data_.loc[data_.name == 'Viktoria Alexeeva','birthday'] = '13th April, 1995'\n",
    "data_.loc[data_.name == 'Hayes Hargrove','birthday'] = '20th December, 1979'\n",
    "data_.loc[data_.name == 'Cisco Rosado','birthday'] = '29th June, 1979'\n",
    "data_.loc[data_.name == 'Cherie Thibodeaux','birthday'] = '11th September, 1975'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datetime(date):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        date_components = date.replace(',','').split(' ')\n",
    "\n",
    "        date_components = ([date_components[0].replace('st', '').replace('nd', '').replace('rd', '').replace('th', '')]\n",
    "                           + date_components[1:])\n",
    "\n",
    "        date = \"-\".join(date_components)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    return date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zodiac_sign(day, month): \n",
    "    # checks month and date within the valid range \n",
    "    # of a specified zodiac \n",
    "    if month == 12: \n",
    "        return 'sagittarius' if (day < 22) else 'capricorn'\n",
    "\n",
    "    elif month == 1: \n",
    "        return 'capricorn' if (day < 20) else 'aquarius'\n",
    "\n",
    "    elif month == 2: \n",
    "        return 'aquarius' if (day < 19) else 'pisces'\n",
    "\n",
    "    elif month == 3: \n",
    "        return 'pisces' if (day < 21) else 'aries'\n",
    "\n",
    "    elif month == 4: \n",
    "        return 'aries' if (day < 20) else 'taurus'\n",
    "\n",
    "    elif month == 5: \n",
    "        return 'taurus' if (day < 21) else 'gemini'\n",
    "\n",
    "    elif month == 6: \n",
    "        return 'gemini' if (day < 21) else 'cancer'\n",
    "\n",
    "    elif month == 7: \n",
    "        return 'cancer' if (day < 23) else 'leo'\n",
    "\n",
    "    elif month == 8: \n",
    "        return 'leo' if (day < 23) else 'virgo'\n",
    "\n",
    "    elif month == 9: \n",
    "        return 'virgo' if (day < 23) else 'libra'\n",
    "\n",
    "    elif month == 10: \n",
    "        return 'libra' if (day < 23) else 'scorpio'\n",
    "\n",
    "    elif month == 11: \n",
    "        return 'scorpio' if (day < 22) else 'sagittarius'\n",
    "    \n",
    "    elif day == np.nan or month == np.nan:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "def calculate_age(birthdate): \n",
    "    \n",
    "    if pd.isnull(birthdate):\n",
    "        return np.nan\n",
    "\n",
    "    year = birthdate.year\n",
    "    month = str(birthdate.month)\n",
    "    day = str(birthdate.day)\n",
    "    \n",
    "    age = 2020 - year + int(pd.to_datetime('2020-'+month+'-'+day) <= pd.to_datetime(date.today()))\n",
    "    \n",
    "    return age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_.copy()\n",
    "data_1['birthday'] = data_1['birthday'].apply(process_datetime)\n",
    "data_1['birthday'] = pd.to_datetime(data_1['birthday'], format = '%d-%B-%Y')\n",
    "\n",
    "data_1['sign'] = data_1.birthday.apply(lambda bd: zodiac_sign(bd.day, bd.month))\n",
    "\n",
    "data_1['age'] = data_1.birthday.apply(calculate_age)\n",
    "\n",
    "data_1['n_relationships'] = proc_data.relationships.apply(lambda l: len(eval(l)))\n",
    "\n",
    "data_1 = data_1.rename(columns = {'birthday': 'date_of_birth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = data_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local database 'Kaggle Movie Database' and upload data\n",
    "# extracted from https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    "\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"gossip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"CREATE CONSTRAINT UniquePersonNameConstraint ON (p:Person) ASSERT p.name IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'UniquePersonNameConstraint',\n",
       "  'description': 'CONSTRAINT ON ( person:Person ) ASSERT (person.name) IS UNIQUE',\n",
       "  'details': \"Constraint( id=2, name='UniquePersonNameConstraint', type='UNIQUENESS', schema=(:Person {name}), ownedIndex=1 )\"}]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check creation of constraints\n",
    "graph.run(\"CALL db.constraints()\").data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Person nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count(p)': 5226}]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in proc_data.iterrows():\n",
    "    graph.run('''\n",
    "        MERGE (p:Person {name:$name})\n",
    "            ON CREATE SET\n",
    "                  p.name = $name,\n",
    "                  p.dateOfBirth = $date_of_birth,\n",
    "                  p.age = toInteger($age),\n",
    "                  p.heightCm = toFloat($height_cm),\n",
    "                  p.weightKg = toFloat($weight_kg),\n",
    "                  p.eyeColor = $eye_color,\n",
    "                  p.hairColor = $hair_color,\n",
    "                  p.sign = $sign,\n",
    "                  p.sexuality = $sexuality,\n",
    "                  p.ethnicity = $ethnicity,\n",
    "                  p.nationality = $nationality,\n",
    "                  p.occupation = $occupation,\n",
    "                  p.religion = $religion,\n",
    "                  p.n_relationships = toInteger($n_relationships)\n",
    "                  ''', \n",
    "        parameters = {\n",
    "          'name': row['name'],\n",
    "          'date_of_birth': str(row.date_of_birth),\n",
    "          'age': row.age,\n",
    "          'height_cm': row.height_cm,\n",
    "          'weight_kg': row.weight_kg,\n",
    "          'eye_color': row.eye_color,\n",
    "          'hair_color': row.hair_color,\n",
    "          'sign': row.sign,\n",
    "          'sexuality': row.sexuality,\n",
    "          'ethnicity': row.ethnicity,\n",
    "          'nationality': row.nationality,\n",
    "          'occupation': row.occupation,\n",
    "          'religion': row.religion,\n",
    "          'n_relationships': row.n_relationships\n",
    "        })\n",
    "    \n",
    "    \n",
    "# check creation of movie nodes\n",
    "\n",
    "graph.run('match (p:Person) return count(p)').data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'COUNT(r)': 14076}]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in proc_data.iterrows():\n",
    "    graph.run('''\n",
    "        WITH apoc.convert.fromJsonList($relationships) AS relationships\n",
    "        UNWIND relationships AS relationships_map\n",
    "        WITH relationships_map['name'] AS p2_name,\n",
    "             relationships_map['type'] AS type,\n",
    "             relationships_map['start'] AS start,\n",
    "             relationships_map['end'] AS end,\n",
    "             relationships_map['duration'] AS duration\n",
    "\n",
    "        \n",
    "        MATCH (p1:Person {name:$p1_name}), (p2:Person {name:p2_name})\n",
    "        \n",
    "        MERGE (p1)-[r:RELATIONSHIP]-(p2)\n",
    "            ON CREATE SET\n",
    "                r.type = type,\n",
    "                r.start = start,\n",
    "                r.end = end,\n",
    "                r.duration = duration\n",
    "                  ''', \n",
    "              \n",
    "        parameters = {\n",
    "          'p1_name': row['name'],\n",
    "          'relationships': row.relationships\n",
    "        })\n",
    "    \n",
    "    \n",
    "# check creation of movie nodes\n",
    "\n",
    "graph.run('MATCH (:Person)-[r:RELATIONSHIP]-(:Person) RETURN COUNT(r)').data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People that shared more relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p1.name': 'Ava Gardner', 'p3.name': 'Lana Turner', 'c': 24},\n",
       " {'p1.name': 'Jack Nicholson', 'p3.name': 'Warren Beatty', 'c': 12},\n",
       " {'p1.name': 'Lindsay Lohan', 'p3.name': 'Paris Hilton', 'c': 10},\n",
       " {'p1.name': 'Ryan O Neal', 'p3.name': 'Warren Beatty', 'c': 10},\n",
       " {'p1.name': 'Mick Jagger', 'p3.name': 'Warren Beatty', 'c': 10},\n",
       " {'p1.name': 'Frank Sinatra', 'p3.name': 'John F Kennedy', 'c': 9},\n",
       " {'p1.name': 'Lana Turner', 'p3.name': 'Marlene Dietrich', 'c': 9},\n",
       " {'p1.name': 'Ava Gardner', 'p3.name': 'Marilyn Monroe', 'c': 9},\n",
       " {'p1.name': 'Robert Evans', 'p3.name': 'Warren Beatty', 'c': 9},\n",
       " {'p1.name': 'David Bowie', 'p3.name': 'Mick Jagger', 'c': 8}]"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "MATCH p = (p1:Person)-[r1:RELATIONSHIP]-(p2:Person)-[r2:RELATIONSHIP]-(p3:Person)\n",
    "WHERE p1<>p3 and p1.name < p3.name //and p1.age <= 35 and p3.age <= 35\n",
    "WITH p1, p3, count(distinct(p)) AS c\n",
    "RETURN p1.name, p3.name, c ORDER BY c DESC LIMIT 10\n",
    "'''\n",
    "\n",
    "graph.run(query).data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People up to 40 years old that shared more relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p1.name': 'Lindsay Lohan', 'p3.name': 'Paris Hilton', 'c': 10},\n",
       " {'p1.name': 'Aubrey Graham', 'p3.name': 'James Harden', 'c': 6},\n",
       " {'p1.name': 'Lil Wayne', 'p3.name': 'Soulja Boy', 'c': 6},\n",
       " {'p1.name': 'Shad Moss', 'p3.name': 'Yung Berg', 'c': 5},\n",
       " {'p1.name': 'Lindsay Lohan', 'p3.name': 'Sienna Miller', 'c': 5},\n",
       " {'p1.name': 'Jenna Shea', 'p3.name': 'Kat Stacks', 'c': 5},\n",
       " {'p1.name': 'Rob Kardashian', 'p3.name': 'Soulja Boy', 'c': 5},\n",
       " {'p1.name': 'French Montana', 'p3.name': 'James Harden', 'c': 4},\n",
       " {'p1.name': 'Alexis Sky', 'p3.name': 'Blac Chyna', 'c': 4},\n",
       " {'p1.name': 'James Harden', 'p3.name': 'Lil Wayne', 'c': 4}]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "MATCH p = (p1:Person)-[r1:RELATIONSHIP]-(p2:Person)-[r2:RELATIONSHIP]-(p3:Person)\n",
    "WHERE p1<>p3 and p1.name < p3.name and p1.age <= 40 and p3.age <= 40\n",
    "WITH p1, p3, count(distinct(p)) AS c\n",
    "RETURN p1.name, p3.name, c ORDER BY c DESC LIMIT 10\n",
    "'''\n",
    "\n",
    "graph.run(query).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.database.Cursor at 0x12504d438>"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize nodes\n",
    "\n",
    "query = '''\n",
    "MATCH (p1:Person {name:$name1})-[r1:RELATIONSHIP]-(p3)-[r2:RELATIONSHIP]-(p2:Person {name:$name2}) \n",
    "return p1, p2, p3, r1, r2\n",
    "'''\n",
    "\n",
    "graph.run(query, parameters = {'name1': 'Rihanna', 'name2': 'Rita Ora'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many squares of data?\n",
    "\n",
    "query = '''\n",
    "MATCH (p1:Person)-[:RELATIONSHIP]-(p2:Person)-[:RELATIONSHIP]-(p3:Person)-[:RELATIONSHIP]-(p4:Person)-[:RELATIONSHIP]-(p1) \n",
    "WHERE p1 <> p3 and p2 <> p4 and p1.name < p3.name and p2.name < p4.name\n",
    "return p1, p2, p3, p4 limit 10\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nodeProjection': {'Person': {'properties': {}, 'label': 'Person'}},\n",
       "  'relationshipProjection': {'RELATIONSHIP': {'orientation': 'UNDIRECTED',\n",
       "    'aggregation': 'DEFAULT',\n",
       "    'type': 'RELATIONSHIP',\n",
       "    'properties': {}}},\n",
       "  'graphName': 'myGraph',\n",
       "  'nodeCount': 5226,\n",
       "  'relationshipCount': 14076,\n",
       "  'createMillis': 70}]"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "CALL gds.graph.create(\n",
    "    'myGraph',\n",
    "    'Person',\n",
    "    {\n",
    "        RELATIONSHIP: {\n",
    "            orientation: 'UNDIRECTED'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "'''\n",
    "\n",
    "graph.run(query).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nodeCount': 5226,\n",
       "  'relationshipCount': 14076,\n",
       "  'bytesMin': 340049,\n",
       "  'bytesMax': 1903232,\n",
       "  'requiredMemory': '[332 KiB ... 1858 KiB]'}]"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "CALL gds.louvain.write.estimate('myGraph', { writeProperty: 'community' })\n",
    "YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory\n",
    "'''\n",
    "\n",
    "graph.run(query).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'communityCount': 289,\n",
       "  'modularity': 0.7795516802748462,\n",
       "  'modularities': [0.543530377173047,\n",
       "   0.7367617725107102,\n",
       "   0.7644527200652552,\n",
       "   0.7795516802748462]}]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "CALL gds.louvain.write('myGraph', { writeProperty: 'community' })\n",
    "YIELD communityCount, modularity, modularities\n",
    "'''\n",
    "\n",
    "graph.run(query).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'David Bowie', 'triangleCount': 5},\n",
       " {'name': 'Missy Elliott', 'triangleCount': 3},\n",
       " {'name': 'Da Brat', 'triangleCount': 3},\n",
       " {'name': 'Rocco Siffredi', 'triangleCount': 3},\n",
       " {'name': 'Jesse Jane', 'triangleCount': 3},\n",
       " {'name': 'Marilyn Monroe', 'triangleCount': 2},\n",
       " {'name': 'Joan Crawford', 'triangleCount': 2},\n",
       " {'name': 'Marlon Brando', 'triangleCount': 2},\n",
       " {'name': 'Howard Hughes', 'triangleCount': 2},\n",
       " {'name': 'Gianna Michaels', 'triangleCount': 2},\n",
       " {'name': 'Britney Stevens', 'triangleCount': 2},\n",
       " {'name': 'Belladonna', 'triangleCount': 2},\n",
       " {'name': 'Joan Jett', 'triangleCount': 2},\n",
       " {'name': 'Trina', 'triangleCount': 2},\n",
       " {'name': 'Lori Mattox', 'triangleCount': 2},\n",
       " {'name': 'Queenie', 'triangleCount': 2},\n",
       " {'name': 'Mick Ronson', 'triangleCount': 2},\n",
       " {'name': 'Iggy Pop', 'triangleCount': 2},\n",
       " {'name': 'Errol Flynn', 'triangleCount': 2},\n",
       " {'name': 'Laurence Olivier', 'triangleCount': 2},\n",
       " {'name': 'Karrine Steffans', 'triangleCount': 2},\n",
       " {'name': 'Kristen Stewart', 'triangleCount': 1},\n",
       " {'name': 'Soko', 'triangleCount': 1},\n",
       " {'name': 'Robert Pattinson', 'triangleCount': 1},\n",
       " {'name': 'Madonna', 'triangleCount': 1},\n",
       " {'name': 'Amber Rose', 'triangleCount': 1},\n",
       " {'name': 'Tommy Lee', 'triangleCount': 1},\n",
       " {'name': 'Ingrid Casares', 'triangleCount': 1},\n",
       " {'name': 'Warren Beatty', 'triangleCount': 1},\n",
       " {'name': 'Sandra Bernhard', 'triangleCount': 1},\n",
       " {'name': 'Tim Mosley', 'triangleCount': 1},\n",
       " {'name': 'Nikki Mudarris', 'triangleCount': 1},\n",
       " {'name': 'Rosa Acosta', 'triangleCount': 1},\n",
       " {'name': 'Ruby Rose', 'triangleCount': 1},\n",
       " {'name': 'Lyndsey Anne', 'triangleCount': 1},\n",
       " {'name': 'Lola Van Vorst', 'triangleCount': 1},\n",
       " {'name': 'Paul Newman', 'triangleCount': 1},\n",
       " {'name': 'Robert Wagner', 'triangleCount': 1},\n",
       " {'name': 'Bree Olson', 'triangleCount': 1},\n",
       " {'name': 'Brooke Mueller', 'triangleCount': 1},\n",
       " {'name': 'Lexington Steele', 'triangleCount': 1},\n",
       " {'name': 'Ace', 'triangleCount': 1},\n",
       " {'name': 'Kelly Lebrock', 'triangleCount': 1},\n",
       " {'name': 'Michelle Phillips', 'triangleCount': 1},\n",
       " {'name': 'Nina Hartley', 'triangleCount': 1},\n",
       " {'name': 'Moana Pozzi', 'triangleCount': 1},\n",
       " {'name': 'Pleasant Gehman', 'triangleCount': 1},\n",
       " {'name': 'Jessie Lee', 'triangleCount': 1},\n",
       " {'name': 'Joanna Angel', 'triangleCount': 1},\n",
       " {'name': 'Jessica Jaymes', 'triangleCount': 1},\n",
       " {'name': 'Allen Iverson', 'triangleCount': 1},\n",
       " {'name': 'Cherie Currie', 'triangleCount': 1},\n",
       " {'name': 'Danny Bonaduce', 'triangleCount': 1},\n",
       " {'name': 'Gloria Vanderbilt', 'triangleCount': 1},\n",
       " {'name': 'Lana Turner', 'triangleCount': 1},\n",
       " {'name': 'Angie Bowie', 'triangleCount': 1},\n",
       " {'name': 'Lou Reed', 'triangleCount': 1},\n",
       " {'name': 'Shelley Winters', 'triangleCount': 1},\n",
       " {'name': 'Vivien Leigh', 'triangleCount': 1},\n",
       " {'name': 'Charlotte Lewis', 'triangleCount': 1},\n",
       " {'name': 'Elizabeth Hurley', 'triangleCount': 1},\n",
       " {'name': 'William Annesley', 'triangleCount': 1},\n",
       " {'name': 'Charlie Sheen', 'triangleCount': 1},\n",
       " {'name': 'Jack Nicholson', 'triangleCount': 1},\n",
       " {'name': 'Dave Navarro', 'triangleCount': 1},\n",
       " {'name': 'Billy Idol', 'triangleCount': 1},\n",
       " {'name': 'Janice Dickinson', 'triangleCount': 1},\n",
       " {'name': 'Jane Fonda', 'triangleCount': 1}]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "CALL gds.triangleCount.stream('myGraph')\n",
    "YIELD nodeId, triangleCount\n",
    "WITH nodeId, triangleCount WHERE triangleCount > 0\n",
    "RETURN gds.util.asNode(nodeId).name AS name, triangleCount\n",
    "ORDER BY triangleCount DESC\n",
    "'''\n",
    "\n",
    "graph.run(query).data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
