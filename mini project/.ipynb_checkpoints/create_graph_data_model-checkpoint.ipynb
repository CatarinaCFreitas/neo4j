{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extracted from https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    "\n",
    "# info on cast and crew\n",
    "credits = pd.read_csv('data/credits.csv')\n",
    "\n",
    "# info on movie keywords\n",
    "keywords = pd.read_csv('data/keywords.csv')\n",
    "\n",
    "# properties of movies\n",
    "movies_metadata = pd.read_csv('data/movies_metadata.csv', low_memory=False)\n",
    "\n",
    "# sample with ratings of 671 users and 9066 movies\n",
    "ratings_small = pd.read_csv('data/ratings_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the movies rated by the small sample of users\n",
    "\n",
    "rated_movies = ratings_small.movieId.unique()\n",
    "\n",
    "\n",
    "# exclude invalid ids from movie dataset\n",
    "\n",
    "def convert_to_int_or_nan(obj):\n",
    "    try:\n",
    "        return int(obj)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "movies_metadata.id = movies_metadata.id.apply(lambda i: convert_to_int_or_nan(i))\n",
    "print('nr of invalid movie ids: ', movies_metadata.id.isnull().sum())\n",
    "\n",
    "\n",
    "# Select the rated movies that were already released and drop duplicates\n",
    "\n",
    "movies_ = movies_metadata[(movies_metadata.id.isin(rated_movies)) & (movies_metadata.status == 'Released')]\n",
    "movies_ = movies_.drop_duplicates(subset = ['id']).reset_index(drop = True)\n",
    "movies_.id = movies_.id.astype(int)\n",
    "print('movies shape: ', movies_.shape)\n",
    "\n",
    "# convert boolean feature to 0 and 1\n",
    "movies_['belongs_to_collection'] = (~movies_['belongs_to_collection'].isnull()).astype(int)\n",
    "\n",
    "# correct empty release date\n",
    "movies_.loc[movies_.original_title == 'Anybody\\'s Son Will Do', 'release_date'] = '1983-12-31'\n",
    "\n",
    "valid_movies = movies_.id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data from credits, keywords and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the subset of data from credits, keywords and ratings corresponding to the valid movies\n",
    "\n",
    "credits_ = credits[credits.id.isin(valid_movies)]\n",
    "credits_ = credits_.drop_duplicates(subset = ['id']).reset_index(drop = True)\n",
    "print('credits shape: ', credits_.shape)\n",
    "      \n",
    "keywords_ = keywords[keywords.id.isin(valid_movies)]\n",
    "keywords_ = keywords_.drop_duplicates(subset = ['id']).reset_index(drop = True)\n",
    "print('keywords shape: ', keywords_.shape)\n",
    "\n",
    "ratings_ = ratings_small[ratings_small.movieId.isin(valid_movies)].reset_index(drop = True)\n",
    "print('ratings shape: ', ratings_.shape)\n",
    "print('nr movies with ratings: ', ratings_.movieId.nunique())\n",
    "print('nr users with ratings: ', ratings_.userId.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean keywords dataset to keep only keywords associated with at least 3 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to count frequency of keywords\n",
    "\n",
    "keywords_vocab = {}\n",
    "\n",
    "for index, row in keywords_.iterrows():\n",
    "    \n",
    "    list_of_dicts = eval(row.keywords)\n",
    "    \n",
    "    words = [dict_['name'] for dict_ in list_of_dicts]\n",
    "    \n",
    "    for w in words:\n",
    "        \n",
    "        if w in keywords_vocab:\n",
    "            keywords_vocab[w] += 1\n",
    "        else:\n",
    "            keywords_vocab[w] = 1\n",
    "            \n",
    "            \n",
    "# build dataframe from dictionary    \n",
    "\n",
    "vocab = pd.DataFrame.from_dict(keywords_vocab, orient = 'index', columns = ['counts']).sort_values(by = 'counts')\n",
    "\n",
    "\n",
    "# filter vocabulary to keep words with more than 3 counts\n",
    "\n",
    "vocab_clean_list = vocab[vocab.counts>=3].index.tolist()\n",
    "\n",
    "\n",
    "# clean original dataset with filtered vocabulary\n",
    "\n",
    "keywords_clean = keywords_.copy()\n",
    "\n",
    "for index, row in keywords_clean.iterrows():\n",
    "    \n",
    "    list_of_dicts = eval(row.keywords)\n",
    "    \n",
    "    clean_dicts = [{'id': dict_['id'], 'name': dict_['name']} for dict_ in list_of_dicts if dict_['name'] in vocab_clean_list]\n",
    "    \n",
    "    keywords_clean.loc[index,'keywords_filtered'] = str(clean_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define graph model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](graph_model/graph_model_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local database 'Kaggle Movie Database' and upload data\n",
    "# extracted from https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    "\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"ilovemovies\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique constraints before loading the data\n",
    "\n",
    "graph.run(\"CREATE CONSTRAINT UniqueMovieIdConstraint ON (m:Movie) ASSERT m.id IS UNIQUE\").data()\n",
    "graph.run(\"CREATE CONSTRAINT UniqueUserIdConstraint ON (u:User) ASSERT u.id IS UNIQUE\").data()\n",
    "graph.run(\"CREATE CONSTRAINT UniqueActorIdConstraint ON (a:Actor) ASSERT a.id IS UNIQUE\").data()\n",
    "graph.run(\"CREATE CONSTRAINT UniqueCrewIdConstraint ON (c:Crew) ASSERT c.id IS UNIQUE\").data()\n",
    "graph.run(\"CREATE CONSTRAINT UniqueKeywordIdConstraint ON (k:Keyword) ASSERT k.id IS UNIQUE\").data()\n",
    "graph.run(\"CREATE CONSTRAINT UniqueGenreIdConstraint ON (g:Genre) ASSERT g.id IS UNIQUE\").data()\n",
    "graph.run(\"CREATE CONSTRAINT UniqueProductionCompanyIdConstraint ON (p:ProductionCompany) ASSERT p.id IS UNIQUE\").data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check creation of constraints\n",
    "graph.run(\"CALL db.constraints()\").data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing nodes and relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import movie nodes\n",
    "\n",
    "for index, row in movies_.iterrows():\n",
    "    graph.run('''\n",
    "        MERGE (m:Movie {id:toInteger($id)})\n",
    "            ON CREATE SET\n",
    "                  m.name = $title,\n",
    "                  m.releaseDate = date($release_date),\n",
    "                  m.runtime = toFloat($runtime),\n",
    "                  m.popularity = toFloat($popularity),\n",
    "                  m.voteAverage = toFloat($vote_average),\n",
    "                  m.voteCount = toInteger($vote_count),\n",
    "                  m.originalLanguage = $original_language,\n",
    "                  m.budget = toInteger($budget),\n",
    "                  m.revenue = toInteger($revenue),\n",
    "                  m.belongsToCollection = toInteger($belongs_to_collection)                    \n",
    "                  ''', \n",
    "        parameters = {\n",
    "          'id': row.id,\n",
    "          'title': row.title,\n",
    "          'release_date': row.release_date,\n",
    "          'runtime': row.runtime,\n",
    "          'popularity': row.popularity,\n",
    "          'vote_average': row.vote_average,\n",
    "          'vote_count': row.vote_count,\n",
    "          'original_language': row.original_language,\n",
    "          'budget': row.budget,\n",
    "          'revenue': row.revenue,\n",
    "          'belongs_to_collection': row.belongs_to_collection})\n",
    "    \n",
    "    \n",
    "# check creation of movie nodes\n",
    "\n",
    "graph.run('match (m:Movie) return count(m)').data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import user nodes\n",
    "\n",
    "for index, row in ratings_[['userId']].drop_duplicates().iterrows():\n",
    "    graph.run('''\n",
    "        MERGE (u:User {id:$user_id})\n",
    "            ON CREATE SET\n",
    "                      u.name = $user_id\n",
    "        ''', \n",
    "        parameters = {\n",
    "            'user_id': int(row.userId),\n",
    "        })\n",
    "    \n",
    "    \n",
    "# check creation of user nodes\n",
    "\n",
    "graph.run('match (u:User) return count(u)').data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between movies and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rating relationships between users and movies\n",
    "\n",
    "for index, row in ratings_.iterrows():\n",
    "    graph.run('''\n",
    "        MATCH (u:User {id:$user_id}), (m:Movie {id: $movie_id})\n",
    "        MERGE (u)-[r:RATED]->(m)\n",
    "            ON CREATE SET\n",
    "                r.rating = $rating,\n",
    "                r.timestamp = datetime({epochSeconds: $timestamp})\n",
    "            ''', \n",
    "        parameters = {\n",
    "            'user_id': int(row.userId),\n",
    "            'movie_id': int(row.movieId),\n",
    "            'rating': row.rating,\n",
    "            'timestamp': int(row.timestamp)\n",
    "        })\n",
    "    \n",
    "    \n",
    "graph.run('match (:User)-[r:RATED]->(:Movie) return count(r)').data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actor and crew nodes and their relationships with movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import actors, crew (writers and directors) and their relationships with movies\n",
    "# relationships are created with properties job (and job2 if applicable) to include crew function (writor/director)\n",
    "\n",
    "for index, row in credits_.iterrows():\n",
    "    graph.run('''\n",
    "        WITH replace($cast_string, \": None\", \": \\'None\\'\") AS cast_string_corrected\n",
    "        WITH apoc.convert.fromJsonList(cast_string_corrected) AS cast_json_list\n",
    "        UNWIND cast_json_list AS cast_json\n",
    "        WITH cast_json['id'] AS cast_id,\n",
    "             cast_json['name'] AS cast_name,\n",
    "             cast_json['gender'] AS cast_gender\n",
    "        WHERE cast_json['order'] < 5\n",
    "        \n",
    "        MERGE (a:Actor {id:cast_id})\n",
    "            ON CREATE SET\n",
    "                a.name = cast_name,\n",
    "                a.gender = cast_gender\n",
    " \n",
    "        WITH a\n",
    "        MATCH (m:Movie {id: $movie_id}) \n",
    "        MERGE (a)-[:ACTED_IN]->(m)\n",
    "        \n",
    "        \n",
    "        WITH replace($crew_string, \": None\", \": \\'None\\'\") AS crew_string_corrected1\n",
    "        WITH replace(crew_string_corrected1, \"Screenplay\", \"Writer\") AS crew_string_corrected2\n",
    "        WITH apoc.convert.fromJsonList(crew_string_corrected2) AS crew_json_list\n",
    "        UNWIND crew_json_list AS crew_json\n",
    "        \n",
    "        WITH crew_json['id'] AS crew_id,\n",
    "             crew_json['name'] AS crew_name,\n",
    "             crew_json['job'] AS crew_job\n",
    "        WHERE crew_json['job'] IN ['Writer', 'Director']\n",
    "        \n",
    "        MERGE (c:Crew {id:crew_id})\n",
    "            ON CREATE SET\n",
    "                c.name = crew_name   \n",
    "                \n",
    "        WITH c, crew_job\n",
    "        MATCH (m:Movie {id: $movie_id}) \n",
    "        MERGE (c)-[r:WORKED_IN]->(m)\n",
    "            ON CREATE SET\n",
    "                r.job = crew_job\n",
    "            ON MATCH SET\n",
    "                r.job2 = CASE WHEN r.job <> crew_job THEN crew_job END          \n",
    "        ''', \n",
    "        parameters = {\n",
    "            'cast_string': row.cast,\n",
    "            'crew_string': row.crew,\n",
    "            'movie_id': int(row.id)\n",
    "        })\n",
    "    \n",
    "    \n",
    "# check creation of nodes and relationships\n",
    "\n",
    "print(graph.run('match (a:Actor) return count(a)').data())\n",
    "\n",
    "print(graph.run('match (:Actor)-[r:ACTED_IN]->(:Movie) return count(r)').data())\n",
    "\n",
    "print(graph.run('match (c:Crew) return count(c)').data())\n",
    "\n",
    "print(graph.run('match (:Crew)-[r:WORKED_IN]->(:Movie) return count(r)').data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace WORKED_IN relationship with WROTE or DIRECTED\n",
    "\n",
    "graph.run('''\n",
    "    MATCH (c:Crew)-[r:WORKED_IN]->(m:Movie) WHERE r.job = 'Writer' or r.job2 = 'Writer'\n",
    "    MERGE (c)-[:WROTE]->(m)\n",
    "''')\n",
    "\n",
    "print(graph.run('MATCH (:Crew)-[r:WROTE]->(:Movie) RETURN count(r)').data())\n",
    "\n",
    "\n",
    "graph.run('''\n",
    "    MATCH (c:Crew)-[r:WORKED_IN]->(m:Movie) WHERE r.job = 'Director' or r.job2 = 'Director'\n",
    "    MERGE (c)-[:DIRECTED]->(m)\n",
    "''')\n",
    "\n",
    "print(graph.run('MATCH (:Crew)-[r:DIRECTED]->(:Movie) RETURN count(r)').data())\n",
    "\n",
    "\n",
    "graph.run('MATCH (:Crew)-[r:WORKED_IN]->(:Movie) DELETE r')\n",
    "\n",
    "print(graph.run('MATCH (:Crew)-[r:WORKED_IN]->(:Movie) RETURN count(r)').data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genres and relationships with movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in movies_.iterrows():\n",
    "    graph.run('''\n",
    "    \n",
    "        WITH apoc.convert.fromJsonList($genres_string) AS genres_json_list\n",
    "        UNWIND genres_json_list AS genres_json\n",
    "        WITH genres_json['id'] AS genre_id,\n",
    "             genres_json['name'] AS genre_name\n",
    "        \n",
    "        MERGE (g:Genre {id:genre_id})\n",
    "            ON CREATE SET\n",
    "                g.name = genre_name\n",
    " \n",
    "        WITH g\n",
    "        MATCH (m:Movie {id: $movie_id}) \n",
    "        MERGE (m)-[:BELONGS_TO]->(g)\n",
    "\n",
    "        ''', \n",
    "        parameters = {\n",
    "            'genres_string': row.genres,\n",
    "            'movie_id': int(row.id)\n",
    "        })\n",
    "    \n",
    "    \n",
    "# check creation of nodes and relationships\n",
    "\n",
    "print(graph.run('match (g:Genre) return count(g)').data())\n",
    "\n",
    "print(graph.run('match (:Movie)-[r:BELONGS_TO]->(:Genre) return count(r)').data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production companies and relationships with movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in movies_.iterrows():\n",
    "    graph.run('''\n",
    "    \n",
    "        WITH apoc.convert.fromJsonList($companies_string) AS companies_json_list\n",
    "        UNWIND companies_json_list AS companies_json\n",
    "        WITH companies_json['id'] AS company_id,\n",
    "             companies_json['name'] AS company_name\n",
    "        \n",
    "        MERGE (p:ProductionCompany {id:company_id})\n",
    "            ON CREATE SET\n",
    "                p.name = company_name\n",
    " \n",
    "        WITH p\n",
    "        MATCH (m:Movie {id: $movie_id}) \n",
    "        MERGE (p)-[:PRODUCED]->(m)\n",
    "\n",
    "        ''', \n",
    "        parameters = {\n",
    "            'companies_string': row.production_companies,\n",
    "            'movie_id': int(row.id)\n",
    "        })\n",
    "    \n",
    "    \n",
    "# check creation of nodes and relationships\n",
    "\n",
    "print(graph.run('match (p:ProductionCompany) return count(p)').data())\n",
    "\n",
    "print(graph.run('match (:ProductionCompany)-[r:PRODUCED]->(:Movie) return count(r)').data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords and relationships with movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in keywords_clean.iterrows():\n",
    "    graph.run('''\n",
    "    \n",
    "        WITH apoc.convert.fromJsonList($keys_string) AS keys_json_list\n",
    "        UNWIND keys_json_list AS keys_json\n",
    "        WITH keys_json['id'] AS key_id,\n",
    "             keys_json['name'] AS key_name\n",
    "        \n",
    "        MERGE (k:Keyword {id:key_id})\n",
    "            ON CREATE SET\n",
    "                k.name = key_name\n",
    " \n",
    "        WITH k\n",
    "        MATCH (m:Movie {id: $movie_id}) \n",
    "        MERGE (k)-[:DESCRIBES]->(m)\n",
    "\n",
    "        ''', \n",
    "        parameters = {\n",
    "            'keys_string': row.keywords_filtered,\n",
    "            'movie_id': int(row.id)\n",
    "        })\n",
    "    \n",
    "    \n",
    "# check creation of nodes and relationships\n",
    "\n",
    "print(graph.run('match (k:Keyword) return count(k)').data())\n",
    "\n",
    "print(graph.run('match (:Keyword)-[r:DESCRIBES]->(:Movie) return count(r)').data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate database schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](graph_model/neo4j_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
